{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_VISITS</th>\n",
       "      <th>TOTAL_SPENT</th>\n",
       "      <th>AVRG_SPENT_PER_VISIT</th>\n",
       "      <th>HAS_CREDIT_CARD</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>PKNIT_DRES</th>\n",
       "      <th>PBLOUSES</th>\n",
       "      <th>PJACKETS</th>\n",
       "      <th>PCAR_PNTS</th>\n",
       "      <th>...</th>\n",
       "      <th>CLUSTYPE_8</th>\n",
       "      <th>CLUSTYPE_15</th>\n",
       "      <th>CLUSTYPE_11</th>\n",
       "      <th>CLUSTYPE_18</th>\n",
       "      <th>CLUSTYPE_5</th>\n",
       "      <th>CLUSTYPE_23</th>\n",
       "      <th>CLUSTYPE_38</th>\n",
       "      <th>CLUSTYPE_3</th>\n",
       "      <th>CLUSTYPE_12</th>\n",
       "      <th>CLUSTYPE_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>0.095728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.033349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.045301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21735</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.009904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21736</th>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>0.024107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21737</th>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>0.073549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21738</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.045926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21739</th>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21740 rows √ó 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TOTAL_VISITS  TOTAL_SPENT  AVRG_SPENT_PER_VISIT  HAS_CREDIT_CARD  \\\n",
       "0          0.008772     0.016324              0.095728              0.0   \n",
       "1          0.026316     0.011417              0.033349              1.0   \n",
       "2          0.008772     0.003377              0.019803              0.0   \n",
       "3          0.061404     0.037541              0.054840              1.0   \n",
       "4          0.000000     0.003840              0.045301              0.0   \n",
       "...             ...          ...                   ...              ...   \n",
       "21735      0.008772     0.001689              0.009904              0.0   \n",
       "21736      0.043860     0.012421              0.024107              0.0   \n",
       "21737      0.070175     0.056594              0.073549              0.0   \n",
       "21738      0.017544     0.011770              0.045926              0.0   \n",
       "21739      0.035088     0.024630              0.057617              1.0   \n",
       "\n",
       "       PSWEATERS  PKNIT_TOPS  PKNIT_DRES  PBLOUSES  PJACKETS  PCAR_PNTS  ...  \\\n",
       "0           0.18        0.00        0.00      0.30      0.00       0.25  ...   \n",
       "1           0.26        0.16        0.00      0.00      0.00       0.18  ...   \n",
       "2           1.00        0.00        0.00      0.00      0.00       0.00  ...   \n",
       "3           0.38        0.00        0.05      0.06      0.20       0.17  ...   \n",
       "4           0.20        0.20        0.00      0.00      0.00       0.00  ...   \n",
       "...          ...         ...         ...       ...       ...        ...  ...   \n",
       "21735       0.00        0.00        0.39      0.00      0.00       0.00  ...   \n",
       "21736       0.02        0.00        0.00      0.06      0.22       0.03  ...   \n",
       "21737       0.29        0.04        0.01      0.14      0.23       0.12  ...   \n",
       "21738       0.18        0.00        0.03      0.11      0.00       0.00  ...   \n",
       "21739       0.21        0.09        0.00      0.21      0.24       0.00  ...   \n",
       "\n",
       "       CLUSTYPE_8  CLUSTYPE_15  CLUSTYPE_11  CLUSTYPE_18  CLUSTYPE_5  \\\n",
       "0             0.0          0.0          0.0          0.0         0.0   \n",
       "1             0.0          0.0          0.0          0.0         0.0   \n",
       "2             0.0          0.0          0.0          0.0         0.0   \n",
       "3             0.0          0.0          0.0          0.0         0.0   \n",
       "4             0.0          0.0          0.0          0.0         0.0   \n",
       "...           ...          ...          ...          ...         ...   \n",
       "21735         0.0          0.0          0.0          0.0         0.0   \n",
       "21736         0.0          0.0          0.0          0.0         0.0   \n",
       "21737         0.0          1.0          0.0          0.0         0.0   \n",
       "21738         0.0          0.0          0.0          0.0         0.0   \n",
       "21739         0.0          0.0          0.0          0.0         0.0   \n",
       "\n",
       "       CLUSTYPE_23  CLUSTYPE_38  CLUSTYPE_3  CLUSTYPE_12  CLUSTYPE_-1  \n",
       "0              0.0          0.0         0.0          0.0          0.0  \n",
       "1              0.0          0.0         0.0          0.0          0.0  \n",
       "2              0.0          0.0         0.0          0.0          0.0  \n",
       "3              0.0          0.0         0.0          0.0          0.0  \n",
       "4              0.0          0.0         0.0          0.0          1.0  \n",
       "...            ...          ...         ...          ...          ...  \n",
       "21735          0.0          0.0         0.0          0.0          0.0  \n",
       "21736          0.0          0.0         0.0          1.0          0.0  \n",
       "21737          0.0          0.0         0.0          0.0          0.0  \n",
       "21738          0.0          1.0         0.0          0.0          0.0  \n",
       "21739          0.0          0.0         0.0          0.0          1.0  \n",
       "\n",
       "[21740 rows x 69 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"../datasets/final_clothing_store.csv\"\n",
    "\n",
    "data = pd.read_csv(file_name)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 35}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = data.drop(columns = ['RESP'])\n",
    "Y = data['RESP'].values\n",
    "\n",
    "knn = KNeighborsClassifier(weights=\"distance\")\n",
    "\n",
    "grid_dictionary = {'n_neighbors': np.array([s for s in range(1, 36)])}\n",
    "\n",
    "cv = GridSearchCV(knn, grid_dictionary, cv=10)\n",
    "\n",
    "cv.fit(X, Y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 49}\n"
     ]
    }
   ],
   "source": [
    "# continue running with n_neighbors > 35, since a maximum hasn't been discovered yet\n",
    "grid_dictionary = {'n_neighbors': np.array([s for s in range(36, 50)])}\n",
    "\n",
    "cv = GridSearchCV(knn, grid_dictionary, cv=10)\n",
    "\n",
    "cv.fit(X, Y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 61}\n"
     ]
    }
   ],
   "source": [
    "# and ..... continue running with n_neighbors > 49, since a maximum still hasn't been discovered yet\n",
    "grid_dictionary = {'n_neighbors': np.array([s for s in range(50, 75)])}\n",
    "\n",
    "cv = GridSearchCV(knn, grid_dictionary, cv=10)\n",
    "\n",
    "cv.fit(X, Y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82888684 0.83440662 0.83670653 0.83762649 0.84176633 0.83164673\n",
      " 0.82704692 0.83026679 0.83578657 0.8325667 ]\n",
      "cv_scores mean: 0.8336706531738731\n"
     ]
    }
   ],
   "source": [
    "knn_cv = KNeighborsClassifier(n_neighbors=61, weights=\"distance\")\n",
    "\n",
    "knn_cv_scores = cross_val_score(knn_cv, X, Y, cv=10)\n",
    "\n",
    "print(knn_cv_scores)\n",
    "\n",
    "knn_acc = np.mean(knn_cv_scores)\n",
    "print('cv_scores mean: {}'.format(knn_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84636615 0.8449862  0.85372585 0.84590616 0.85142594 0.83394664\n",
      " 0.84406624 0.83854646 0.84222631 0.84682613]\n",
      "cv_scores mean: 0.8448022079116836\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logregr = linear_model.LogisticRegression(solver='liblinear')\n",
    "logreg_cv_scores = cross_val_score(logregr, X, Y, cv=10)\n",
    "\n",
    "print(logreg_cv_scores)\n",
    "\n",
    "logreg_acc = np.mean(logreg_cv_scores)\n",
    "print('cv_scores mean: {}'.format(logreg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the confidence interval of both classifiers with confidence level: 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.829528694469032, 0.8378126118787143]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# knn classifier\n",
    "sample_mean = knn_acc\n",
    "\n",
    "num_correctly_classified = knn_acc * len(data)\n",
    "num_incorrectly_classified = len(data) - num_correctly_classified\n",
    "sample_variance = ((num_correctly_classified * ((1 - knn_acc) ** 2)) + (num_incorrectly_classified * ((0 - knn_acc) ** 2)))/(len(data) - 1)\n",
    "\n",
    "sample_st_dev = math.sqrt(sample_variance)\n",
    "\n",
    "true_st_dev = sample_st_dev / math.sqrt(len(data))\n",
    "\n",
    "z_value = 1.64 # corresponding to confidence level 90%, from Z-table\n",
    "\n",
    "confidence_interval_knn = [sample_mean - (z_value * (true_st_dev)), sample_mean + (z_value * (true_st_dev))]\n",
    "print(confidence_interval_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8407746262372428, 0.8488297895861244]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# logistic regression classifier \n",
    "sample_mean = logreg_acc\n",
    "\n",
    "num_correctly_classified = logreg_acc * len(data)\n",
    "num_incorrectly_classified = len(data) - num_correctly_classified\n",
    "sample_variance = ((num_correctly_classified * ((1 - logreg_acc) ** 2)) + (num_incorrectly_classified * ((0 - logreg_acc) ** 2)))/(len(data) - 1)\n",
    "\n",
    "sample_st_dev = math.sqrt(sample_variance)\n",
    "\n",
    "true_st_dev = sample_st_dev / math.sqrt(len(data))\n",
    "\n",
    "z_value = 1.64 # corresponding to confidence level 90%, from Z-table\n",
    "\n",
    "confidence_interval_logreg = [sample_mean - (z_value * (true_st_dev)), sample_mean + (z_value * (true_st_dev))]\n",
    "print(confidence_interval_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the confidence intervals of both classifiers with a confidence level of 90%, let's determine whether or not the null hypothesis is true, that is: if there truly is a difference between these two classifiers (ie, the difference in accuracy is not due to random chance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.017479300827966893, -0.010579576816927339, -0.017019319227230878, -0.008279668813247487, -0.00965961361545531, -0.0022999080036798514, -0.01701931922723099, -0.008279668813247376, -0.0064397424103035394, -0.014259429622815012]\n",
      "-0.011131554737810467\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "for i in range(10):\n",
    "    differences.append(knn_cv_scores[i] - logreg_cv_scores[i])\n",
    "print(differences)\n",
    "\n",
    "mean = 0\n",
    "for x in differences:\n",
    "    mean += x\n",
    "\n",
    "mean = mean / len(differences)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0030256883422713618, 0.0030256883422713618]\n"
     ]
    }
   ],
   "source": [
    "variance = 0\n",
    "for x in differences:\n",
    "    variance += ((mean - x) ** 2) / (10 - 1)\n",
    "\n",
    "st_dev = math.sqrt(variance)\n",
    "\n",
    "true_st_dev = st_dev / math.sqrt(10)\n",
    "\n",
    "t_value = 1.86 # corresponding to a confidence level of 90%, and 8 degrees of freedom, from T-table\n",
    "\n",
    "average_difference_interval = [-t_value * true_st_dev, t_value * true_st_dev]\n",
    "print(average_difference_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mean is approximately equal to -0.011, which is less than the lower bound of the interval. Therefore, the null hypothesis is false, and our second classifier, logistic regression, is significantly better than the first, knn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods that I used to improve our classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve my knn classifier, I ran the classifier with 10-fold cross validation with k ranging from 1 to 75 to find the optimal value of k. I discovered that the optimal value of k was equal to 61, and went with that as the final classifier model. Furthermore, I also found that weighing closer data points more heavily than further ones gave me a better accuracy, so I included that in my final model as well. \n",
    "\n",
    "To improve my logistic regression classifier, I ran the classifier with different solver functions, ie : {‚Äònewton-cg‚Äô, ‚Äòlbfgs‚Äô, ‚Äòliblinear‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô}, taken from the sklearn documentation. I discovered that using the 'liblinear' solver gave me the highest accuracy, so I went with that as the final classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential methods of improving our classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way in which we can improve our classifiers is to convert our two classifiers (of which are discrete, ie: they only output a class label when fed a data entry) into probabilistic classifiers (ie: they output a class label as well as the probability of the data entry belonging to that class). Then, we can test the probability threshold (ie: the cut-off probability for the data entry to be classified as one class as opposed to another) at different values, and use the value that gives us the greatest accuracy for the classifier. \n",
    "\n",
    "This should be fairly simple for our Logistic Regression classifier. Logistic Regression aims to find ùëù = ùë†ùëñùëîùëöùëúùëñùëë(ùëéùë•+ùëè), the probability of x belonging to a certain class, by maximizing the objective function: Likelihood. So what we need to do in Logistic Regression to convert it into a probabilistic classifier is to output p as well as the class label for each datapoint. \n",
    "\n",
    "This task of converting discrete classifiers into probabilistic classifiers is more difficult for our knn classifier. The distance function that I've employed in knn is euclidean distance (as well as giving more weight to those points that are closer to the one in question). One possible method we can try is this: When we're evaluating whether a data entry should be classified as yes or no, we calculate the weighted sum of the distances of r datapoints that are classified as yes, call it weight_yes and we calculate the weighted sum of the distances of t datapoints that are classified as no, call it weight_no, where r + t = k. The classifier then classifies the datapoint as the class which corresponds to the sum with less distance, ie: more similarity. When doing this, we can also output the proportions of the sums, so if a data point is classified as yes, we output (along with the class label: yes),\n",
    "weight_yes / (weight_yes + weight_no). This can then be viewed as the probability of it belonging to class: yes. If all k-points nearest to the data point is class: yes, then weight_no = 0, and the probability would equal 1, ie: it is 100% that the class label is correct. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
